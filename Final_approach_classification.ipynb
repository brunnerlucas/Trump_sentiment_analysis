{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf08efd-ab53-4832-a5b6-c7f7aef57347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas_summary\n",
    "#!pip install waterfallcharts\n",
    "#!pip install treeinterpreter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import waterfall_chart\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.tabular import *\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, precision_recall_curve, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2b5024-eb14-4fa0-9ec0-93ba18b94e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "\n",
    "import warnings                              # Disable some warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd5da2-6542-4adf-bf8a-bb9a5e1455aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1= pd.read_parquet(\"part-00000-c39f1c5c-b6aa-4659-8dd9-965ccc023d43-c000.snappy.parquet\")\n",
    "df_2 =pd.read_parquet(\"part-00001-912fc2f1-c131-4414-b9d8-bd9d4095ada5-c000.snappy.parquet\")\n",
    "df = pd.concat([df_1, df_2], axis=0, ignore_index=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47feb538-8e8e-47cb-b029-03e588264951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2391db4-af13-438b-9376-7def3ca9fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e86b3-1fb3-436c-8a88-6bafeb60a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "start_date = pd.to_datetime(\"2017-01-20\")\n",
    "end_date = pd.to_datetime(\"2021-01-20\")\n",
    "df['is_president'] = np.where((df['date'] >= start_date) & (df['date'] <= end_date),1,0)\n",
    "df['is_president'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbebeb14-f23c-497f-aba1-8c289b18b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"dataset.csv\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b12822-7257-4a45-88ab-c544ff903990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert date columns to datetime format with consistent format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df2['Date'] = pd.to_datetime(df2['Date'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Remove time component from df1 to match df2 if df2 only has date (not datetime)\n",
    "df['date'] = df['date'].dt.date\n",
    "df2['Date'] = df2['Date'].dt.date\n",
    "\n",
    "# Merge both datasets on the date column\n",
    "merged_df = pd.merge(df, df2, left_on='date', right_on='Date', how='inner')\n",
    "\n",
    "# Drop duplicate date column from df2 if necessary\n",
    "merged_df.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866d94d-e36f-4184-affc-75c3b2d81529",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57708f-3269-408d-b544-8a6a0fad0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"btc_price_increased\"]=np.where(merged_df[\"btc_price_24h_later\"]-merged_df[\"btc_current_price\"]>0,1,0)\n",
    "columns_to_keep=[\"sentiment_score\",\"btc_current_price\",\"is_president\",\"Value\",\"BTC_Volume\",\"btc_price_increased\"]\n",
    "merged_df=merged_df[columns_to_keep]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a48c20-0227-4357-bc81-f21e3475ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"btc_price_increased\"\n",
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1878862-f790-4c2c-9045-c7f89f72eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model, df_reserved = train_test_split(merged_df, test_size=0.1,random_state=42)\n",
    "print (\"Sample size dataset reserved for prediction: \", df_reserved.shape[0], \"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff8abf1-62bc-4784-b537-6d9dbb5f1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_model[target]\n",
    "\n",
    "# cross validation (80%-20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_model, y, test_size=0.2)\n",
    "print (\"Sample size train dataset: \", X_train.shape)\n",
    "print (\"Sample size test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e9c27-b41a-4780-8486-f8084e0bc5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stepwise function\n",
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.05, \n",
    "                       threshold_out = 0.1, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Arguments:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    Always set threshold_in < threshold_out to avoid infinite looping.\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.Logit(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.Logit(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29973e70-88f8-40f3-83b7-8bbffd73109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes it from the explanatory set (as well as id)\n",
    "#irrelevant_columns = ['id', target]\n",
    "irrelevant_columns = [target]\n",
    "X_train2=X_train.drop(columns=irrelevant_columns)\n",
    "\n",
    "for field in X_train2:\n",
    "    if X_train2[field].isnull().any():\n",
    "        X_train2=X_train2.drop(labels=[field], axis=1)\n",
    "        \n",
    "X_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fadeb9b-3a1c-4ea0-8195-b10f1863da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stepwise_selection(X_train2, y_train)\n",
    "print('resulting features:')\n",
    "print(result) # relevant variables\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7118d-5c86-402b-a058-c6a3d4f3ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds selected features\n",
    "X_train_stepwise=X_train2\n",
    "#for item in X_train2.columns:\n",
    " #   if item not in result:\n",
    "  #      X_train_stepwise=X_train_stepwise.drop(labels=[item],axis=1) #removes the non relevant variables\n",
    "\n",
    "X_train_stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29540b5e-d3e7-46f7-8d70-5b29f2198ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_stepwise = X_test\n",
    "\n",
    "#for item in X_test.columns:\n",
    " #   if item not in result:\n",
    "  #      X_test_stepwise=X_test_stepwise.drop(labels=[item],axis=1) #removes the non relevant variables\n",
    "\n",
    "X_test_stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d8836-be45-46ec-ba24-13f6e2a9f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and heatmap to show correlation between explanatory variables\n",
    "from matplotlib import pyplot as plt        \n",
    "import seaborn as sns                       \n",
    "\n",
    "sns.set(font_scale=1.1)\n",
    "fig, ax = plt.subplots(figsize=(10,10))         \n",
    "sns.heatmap(X_train_stepwise.corr(), annot=True, fmt=\".2f\", linewidths=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9246ac-e9fc-4499-8ec7-9c9c3b67e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stepwise = sm.add_constant(X_train_stepwise)\n",
    "\n",
    "# statsmodels\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y_train,X_train_stepwise)\n",
    "result=logit_model.fit_regularized()\n",
    "print(result.summary2())\n",
    "\n",
    "# print Exp(B) and confidence intervals\n",
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = params\n",
    "conf.columns = ['Lower', 'Upper', 'Odds Ratio']\n",
    "print (\"\\nexp(B) & confidence intervals: \")\n",
    "print (np.exp(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2be117-bb8f-48c2-9260-a4b6715d092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 0.56 # Every probability above 50% is considered a positive\n",
    "\n",
    "train_preds = result.predict(X_train_stepwise)\n",
    "train_preds_binary = (train_preds > cutoff).astype(int)  # Convert to binary labels (0 o 1)\n",
    "train_conf_matrix = confusion_matrix(y_train, train_preds_binary)\n",
    "\n",
    "train_conf_matrix_percentage = train_conf_matrix.astype('float') / train_conf_matrix.sum() * 100\n",
    "train_conf_matrix_percentage = np.round(train_conf_matrix_percentage, 2)\n",
    "\n",
    "print(\"Train dataset confusion matrix\")\n",
    "print(train_conf_matrix_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb723de-131b-4faa-a5b2-7178aa2eafe3",
   "metadata": {},
   "source": [
    "## BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d056486-3771-4159-a2aa-91aac4079e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5194870b-db51-47f9-a32f-f373c0f8f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(merged_df.iloc[:,merged_df.columns != target],\n",
    "                                                    merged_df[target],\n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5cfb9-7c4e-48b5-ad96-034738e7df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: \", x_train.shape)\n",
    "print(\"Test: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbae975-2929-4055-9297-a10f7107cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseRF = RandomForestClassifier(n_estimators = 200,  # The number of trees in the forest\n",
    "                               random_state = 0, # This parameter allows to replicate results\n",
    "                               n_jobs = -1, # The number of jobs to run in parallel (-1 means all processors, 1 no parallelism)\n",
    "                               oob_score = True) # Whether to use out-of-bag samples to estimate the generalization score (increases time)\n",
    "\n",
    "# The OOB score is an estimate of the generalization error of the model, calculated with the data not used to train it.\n",
    "# Since each tree is trained on a bootstrapped sample, they all use approximately 2/3 of the data (this is a mathematical consequence \n",
    "# of random sampling with replacement). Therefore, for each of the learners we have 1/3 of the dataset as Out Of Bag (OOB) observations \n",
    "# which can be used to test the model and estimate its generalisation error. By averaging these OOB error estimates across the trees, \n",
    "# RF produces a robust error estimate for the ensemble during training time at almost no additional computational cost.\n",
    "\n",
    "# other parameters:\n",
    "# criterion{\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
    "# max_depth: int, default=None\n",
    "# min_samples_leaf: int or float, default=1 - The minimum number of samples required to be at a leaf node\n",
    "# min_samples_split: int or float, default=2 - The minimum number of samples required to split an internal node:\n",
    "# max_features{\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\" - The number of features to consider when looking for the best split\n",
    "\n",
    "baseRF.fit(x_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_test = baseRF.predict(x_test)\n",
    "\n",
    "print(\"OOB score: {:.2%}\".format(baseRF.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4f786-4825-4f40-a54d-3057d10c688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'min_samples_leaf' :[1,3,5], \n",
    "    'max_features' : [10,15,20,25,30],\n",
    "    'criterion' : ['gini','entropy'] #,'log_loss']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34e14ee-453c-4220-996c-e561918353a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "cvRF = GridSearchCV(estimator=baseRF, param_grid=param_grid, cv=5, scoring='accuracy') \n",
    "#cv is the number of cross validation iterations to be performed\n",
    "cvRF.fit(x_train,y_train)\n",
    "\n",
    "print (\"Completed in {:0.0f} seconds \".format((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ae337-8bad-4f93-8491-0eb912aa2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows the best combination of criteria found\n",
    "best_params = cvRF.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b45799-11b6-4632-9e28-e457c7a1439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", '{0:0.2%}'.format(cvRF.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f3c95e-2f6f-4141-a195-321eeb98fdad",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f6320-7b67-4649-bd49-0aca41c87f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "model_RF = RandomForestClassifier(n_estimators = 100, \n",
    "                               random_state = 0,\n",
    "                               max_features = 10, #this parameter makes the difference between simple Bagging and Random Forests\n",
    "                               n_jobs = -1,\n",
    "                               oob_score = True,\n",
    "                             criterion = 'entropy')\n",
    "                              # min_samples_leaf = 5)\n",
    "model_RF.fit(x_train,y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_test = model_RF.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21960862-fe6f-473b-8ea0-ef0f7efc68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OOB score: {:.2%}\".format(model_RF.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5134a27-2932-442e-8df3-90de5cfe0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can compare Recall and Precision\n",
    "\n",
    "prob_pred = model_RF.predict_proba(x_test)[:, 1]\n",
    "thresholds = np.arange(0.0, 1.0, step=0.01)\n",
    "recall_scores = [metrics.recall_score(y_test, prob_pred > t) for t in thresholds]\n",
    "precis_scores = [metrics.precision_score(y_test, prob_pred > t) for t in thresholds]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(thresholds, recall_scores, label=\"Recall @ t\")\n",
    "ax.plot(thresholds, precis_scores, label=\"Precision @ t\")\n",
    "ax.axvline(0.5, c=\"gray\", linestyle=\"--\", label=\"Default Threshold\")\n",
    "ax.set_xlabel(\"Threshold\")\n",
    "ax.set_ylabel(\"Metric @ Threshold\")\n",
    "ax.set_box_aspect(1)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875e52c-5d6a-439b-b590-2523ebdc654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model_RF.feature_importances_\n",
    "\n",
    "indexes = np.argsort(importances)[::-1]\n",
    "sorted_imp = importances[indexes]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(len(importances)), importances[indexes], align='center')\n",
    "plt.xticks(range(len(importances)), np.array(model_RF.feature_names_in_)[indexes], rotation=90)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.title(\"Relative feature importances (from 0 to 1)\")\n",
    "for i, bar in enumerate(bars):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
    "             f'{sorted_imp[i]:.2f}', ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a9d8b-4aa8-4a7f-b42c-cb1ef3973bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "cv_scores    = []\n",
    "\n",
    "estimator_range = range(10, 210, 10) #from 5 trees to 100, step 5\n",
    "\n",
    "for n_estimators in estimator_range:\n",
    "    model_RF = RandomForestClassifier(\n",
    "                n_estimators = n_estimators,\n",
    "                max_features = 15, # the previous optimum\n",
    "                oob_score    = False,\n",
    "                n_jobs       = -1, \n",
    "                random_state = 0\n",
    "             )\n",
    "    \n",
    "    model_RF.fit(x_train, y_train)\n",
    "    predictions = model_RF.predict(x_test)\n",
    "    acc=accuracy_score(y_test, predictions)\n",
    "    print(\"% Accuracy of test dataset for {} trees is {:.3f}\".format(n_estimators, acc))\n",
    "    train_scores.append(acc) # storing accuracy from each iteration\n",
    "\n",
    "    # and we also store the accuracy mean obtained from running a 5-fold validation\n",
    "    cvscores = cross_val_score(\n",
    "                estimator = model_RF,\n",
    "                X         = x_train,\n",
    "                y         = y_train,\n",
    "                scoring   = 'accuracy',\n",
    "                cv        = 5\n",
    "             )\n",
    "    cv_scores.append(cvscores.mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea7bfa-bd0d-4e43-9f99-23a0e688f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(estimator_range, train_scores, marker='o', linestyle='-', color='b')\n",
    "plt.title('Accuracy of Test Dataset vs. Number of Trees')\n",
    "plt.xlabel('Number of Trees (n_estimators)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(estimator_range)  # Para mostrar todos los valores en el eje x\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe042b5-c263-4596-aed6-7e7cf371d1ee",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c09417-400c-419f-afee-d146e6734123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from response field\n",
    "X, y = df_model.iloc[:,:-1], df_model.iloc[:,-1]\n",
    "\n",
    "# Partition dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.5, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3753ffa-e457-46eb-a56a-44537e971559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Create DMatrix (recommended for optimization)\n",
    "data_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Define XGBoost Classifier\n",
    "xg_clf = xgb.XGBClassifier(objective='binary:logistic', n_estimators=20, eval_metric='logloss')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2ba90-1722-46aa-9ae8-c922daf7319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "xg_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict class labels\n",
    "y_pred = xg_clf.predict(X_test)\n",
    "\n",
    "# Compute Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "print(\"Precision: {:.2%}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4d264-8f38-4b6f-9be4-37331ef62a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification\n",
    "    'colsample_bytree': 0.3,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'alpha': 10,\n",
    "    'eval_metric': 'precision'  # Metric for precision\n",
    "}\n",
    "\n",
    "# Create DMatrix\n",
    "data_dmatrix = xgb.DMatrix(data=X, label=y)\n",
    "\n",
    "# Perform Cross Validation with precision as the metric\n",
    "cv_results = xgb.cv(\n",
    "    dtrain=data_dmatrix,\n",
    "    params=params,\n",
    "    nfold=3,\n",
    "    num_boost_round=200,\n",
    "    early_stopping_rounds=5,\n",
    "    metrics=\"logloss\",  # Use Precision as the evaluation metric\n",
    "    as_pandas=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Display results\n",
    "cv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9bd89a-f27c-4648-9aa9-508220e63412",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_param_grid = {'learning_rate': [0.01, 0.1, 0.2], 'subsample':[0.3,0.4,0.5]} #subsample controls % of data used\n",
    "gbm = xgb.XGBClassifier()\n",
    "\n",
    "grid_mse = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid, scoring='precision', cv=5, verbose=2)\n",
    "grid_mse.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a5797-4317-45b5-a5cc-92e49c0c47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_clf, importance_type=\"gain\")\n",
    "\n",
    "# weight: number of times the variable has been used\n",
    "# gain: average gain whenever variable is used\n",
    "# cover: how many samples were affected by using each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db5013-25ca-45cd-98f7-add97930ba86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef8149-faf7-4193-8f7c-74e2d634998a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
